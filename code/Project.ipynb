{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Learning embeddings into entropic Wasserstein spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU acceleration\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import skimage.io as io\n",
    "import skimage.transform as transform\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "if torch.cuda.is_available(): print('Using GPU acceleration')\n",
    "else: print('Unable to access CUDA compatible GPU!! Please fix this before running the notebook.')\n",
    "device = torch.device('cuda')\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing t-SNE and Wasserstein embeddings on precomputed image representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('img_representations.h5','r')\n",
    "image_representations = h5f['img_emb'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the t-SNE embedding and the associated visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imscatter(x, y, paths, ax=None, zoom=1, linewidth=0):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0, p in zip(x, y, paths):\n",
    "        try:\n",
    "            im = io.imread(p)\n",
    "        except:\n",
    "            print(p)\n",
    "            continue\n",
    "        im = transform.resize(im,(224,224))\n",
    "        im = OffsetImage(im, zoom=zoom)\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data',\n",
    "                            frameon=True, pad=0.1, \n",
    "                            bboxprops=dict(edgecolor='red',\n",
    "                                           linewidth=linewidth))\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists\n",
    "\n",
    "img_emb_tsne = TSNE(perplexity=30).fit_transform(image_representations)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(img_emb_tsne[:, 0], img_emb_tsne[:, 1]);\n",
    "plt.xticks(()); plt.yticks(());\n",
    "plt.show()\n",
    "\n",
    "import os\n",
    "paths = [\"images_resize/\" + path\n",
    "         for path in sorted(os.listdir(\"images_resize/\"))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "imscatter(img_emb_tsne[:, 0], img_emb_tsne[:, 1], paths, zoom=0.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the entropy regularized Wasserstein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def entropy_regularized_wasserstein_distance(x,y,entropy_level,nb_sinkhorn_iterations,support_size):\n",
    "\n",
    "    D_2 = torch.cdist(x,y,p=2,compute_mode='donot_use_mm_for_euclid_dist')\n",
    "\n",
    "    K = torch.exp(-D_2/entropy_level)\n",
    "\n",
    "    c = torch.ones(support_size).cuda()/support_size\n",
    "    u = torch.ones(support_size).cuda()/support_size\n",
    "    v = torch.ones(support_size).cuda()/support_size\n",
    "\n",
    "    for iter in range(nb_sinkhorn_iterations):\n",
    "        r =  torch.matmul(K, c)\n",
    "        c = v / torch.matmul(K.t(), r)\n",
    "    transport = torch.mm(torch.mm(torch.diag(r), K), torch.diag(c))\n",
    "    return torch.trace(torch.mm(D_2.t(), transport))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Wasserstein-based mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_size = 5\n",
    "\n",
    "class Mapping(nn.Module):\n",
    "    def __init__(self,representation_size,hidden_size,support_size):\n",
    "        super(Mapping, self).__init__()\n",
    "        self.hidden = nn.Linear(representation_size, hidden_size)\n",
    "        self.embedding = nn.Linear(hidden_size, 2*support_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        intermediate_representation = self.hidden(x)\n",
    "        embedded_representation = self.embedding(intermediate_representation)\n",
    "        return embedded_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Wasserstein embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = torch.Tensor(image_representations)\n",
    "trainloader = torch.utils.data.DataLoader(representations, batch_size=128,\n",
    "                                          shuffle=True, num_workers=6)\n",
    "    \n",
    "mapping = Mapping(representation_size=2048,hidden_size=64,support_size=support_size).cuda()\n",
    "optimizer = optim.Adam(mapping.parameters())\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    for i,data in tqdm(enumerate(trainloader,start=0)):\n",
    "        optimizer.zero_grad()\n",
    "        num_representations = data.shape[0]\n",
    "        embeddings = mapping(data.cuda()).view(num_representations,support_size,2).cuda()\n",
    "        loss = torch.zeros(1).cuda()\n",
    "        for i in range(num_representations):\n",
    "            for j in range (num_representations):\n",
    "                if j!=i:\n",
    "                    original_distance = torch.norm(data[i]-data[j]).cuda()\n",
    "                    embeddings_distance = entropy_regularized_wasserstein_distance(embeddings[i],embeddings[j],0.05,20,support_size).cuda()\n",
    "                    loss += (original_distance - embeddings_distance) ** 2    \n",
    "            print(loss)\n",
    "        loss/= math.comb(2,num_representations)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i,representation in enumerate(representations):\n",
    "        for j,representation in enumerate(representations):\n",
    "            if j != i:\n",
    "                original_distance = np.linalg.norm(representation[i]-representation[j],2) ** 2\n",
    "                wasserstein_distance = entropy_regularized_wasserstein_distance(y[i]-y[j])\n",
    "                \n",
    "a1 = np.array([0.,0.])\n",
    "b1 = np.array([0.1,0.1])\n",
    "c1 = np.array([0.2,0.2])\n",
    "d1 = np.array([-0.1,-0.1])\n",
    "\n",
    "A = [a1,b1,c1,d1]\n",
    "\n",
    "\n",
    "a2 = np.array([0.,0.])\n",
    "b2 = np.array([0.05,0.05])\n",
    "c2 = np.array([0.2,0.2])\n",
    "\n",
    "B = [a2,b2,c2]\n",
    "\n",
    "x = torch.tensor([a1,b1,c1,d1])\n",
    "y = torch.tensor([a2,b2,c2])\n",
    "\n",
    "D = np.zeros(shape=(4,3))\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        D[i,j] = np.linalg.norm(A[i]-B[j],2)\n",
    "        \n",
    "#entropy_regularized_wasserstein_distance(x,y,0.05,20,3)\n",
    "print(torch.cdist(x,y,p=2,compute_mode='donot_use_mm_for_euclid_dist'))\n",
    "print(D)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTORCH",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
